name: Production Build, Publish and Release

on: 
  push:
    branches: [ master ]
    paths:
      - 'carla_simulator/**'
      - 'web/**'
      - 'docs/**'
      - 'deployment/docker/**'
      - 'requirements/**'
      - 'pyproject.toml'
      - 'Dockerfile*'
      - 'docker-compose*.yml'
      - '*.py'
      - 'package.json'
      - 'package-lock.json'
      - 'tests/**'
      - 'build-publish-release.yml'
  workflow_dispatch:
    inputs:
      run_tests:
        description: 'Run tests job'
        required: false
        default: true
        type: boolean
      run_build:
        description: 'Run build job'
        required: false
        default: true
        type: boolean
      run_docker_publish:
        description: 'Run docker publish'
        required: false
        default: true
        type: boolean
      run_pypi_publish:
        description: 'Run PyPI publish'
        required: false
        default: true
        type: boolean
      run_github_release:
        description: 'Run GitHub release'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  packages: write

env:
  DOCKER_IMAGE: akshaychikhalkar/carla-driving-simulator-client
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"

jobs:
  # ========================= TESTING PHASE =========================
  
  # Consolidated Testing Matrix
  test-all:
    name: Test
    runs-on: ubuntu-latest
    if: (github.event_name == 'push') || github.event.inputs.run_tests == 'true'
    strategy:
      matrix:
        test-suite: [carla-simulator, web-backend, frontend, integration]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        if: matrix.test-suite != 'frontend'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements/requirements.txt

      - name: Set up Node.js ${{ env.NODE_VERSION }}
        if: matrix.test-suite == 'frontend'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: web/frontend/package-lock.json

      - name: Cache pip dependencies
        if: matrix.test-suite != 'frontend'
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        if: matrix.test-suite != 'frontend'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/requirements.txt
          pip install pytest-cov pytest-html pytest-xdist

      - name: Install frontend dependencies
        if: matrix.test-suite == 'frontend'
        run: npm install
        working-directory: web/frontend

      - name: Run ${{ matrix.test-suite }} tests
        if: matrix.test-suite == 'carla-simulator'
        run: |
          python -m pytest carla_simulator/tests \
            --cov=carla_simulator \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --html=reports/carla-simulator-test-report.html \
            --self-contained-html \
            -v \
            --tb=short \
            --junitxml=reports/carla-simulator-junit.xml
        env:
          TESTING: "true"
          DATABASE_URL: "sqlite:///:memory:"
          CONFIG_TENANT_ID: "1"

      - name: Run ${{ matrix.test-suite }} tests
        if: matrix.test-suite == 'web-backend'
        run: |
          python -m pytest web/backend/tests \
            --cov=web.backend \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --html=reports/web-backend-test-report.html \
            --self-contained-html \
            -v \
            --tb=short \
            --junitxml=reports/web-backend-junit.xml
        env:
          TESTING: "true"
          DATABASE_URL: "sqlite:///:memory:"
          CONFIG_TENANT_ID: "1"
          WEB_FILE_LOGS_ENABLED: "false"
          DISABLE_AUTH_FOR_TESTING: "true"

      - name: Run ${{ matrix.test-suite }} tests
        if: matrix.test-suite == 'frontend'
        run: npm run test:ci
        working-directory: web/frontend
        env:
          CI: true
          NODE_ENV: test

      - name: Run ${{ matrix.test-suite }} tests
        if: matrix.test-suite == 'integration'
        run: |
          # Check if there are any integration tests
          if [ -d "tests" ] && [ "$(ls -A tests)" ]; then
            python -m pytest tests \
              --cov=. \
              --cov-report=xml \
              --cov-report=html \
              --cov-report=term-missing \
              --html=reports/integration-test-report.html \
              --self-contained-html \
              -v \
              --tb=short \
              --junitxml=reports/integration-junit.xml
          else
            echo "No integration tests found - skipping"
            exit 0
          fi
        env:
          TESTING: "true"
          DATABASE_URL: "sqlite:///:memory:"
          CONFIG_TENANT_ID: "1"

      - name: Upload ${{ matrix.test-suite }} test coverage
        if: matrix.test-suite != 'frontend'
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: ${{ matrix.test-suite }}
          name: ${{ matrix.test-suite }}-coverage
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload ${{ matrix.test-suite }} test coverage
        if: matrix.test-suite == 'frontend'
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: web/frontend/coverage/lcov.info
          flags: ${{ matrix.test-suite }}
          name: ${{ matrix.test-suite }}-coverage
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload ${{ matrix.test-suite }} test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ matrix.test-suite }}-test-results
          path: |
            reports/${{ matrix.test-suite }}-test-report.html
            reports/${{ matrix.test-suite }}-junit.xml
            htmlcov/
            ${{ matrix.test-suite == 'frontend' && 'web/frontend/coverage/' || '' }}

  # ========================= VERSION BUMP PHASE =========================
  
  # Version Bump
  version-bump:
    name: Bump Version
    runs-on: ubuntu-latest
    if: (github.event_name == 'push') || github.event.inputs.run_build == 'true'
    outputs:
      version: ${{ steps.bump_version.outputs.newTag }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Get current version
        id: current_version
        run: |
          # Get the latest version tag
          CURRENT_VERSION=$(git describe --tags --match "v[0-9]*" --abbrev=0 2>/dev/null || echo "v1.0.0")
          # Remove 'v' prefix
          CURRENT_VERSION=${CURRENT_VERSION#v}
          echo "current_version=$CURRENT_VERSION" >> $GITHUB_OUTPUT
          echo "Current version: $CURRENT_VERSION"

      - name: Determine version bump type
        id: bump_type
        run: |
          # Get the last commit message
          COMMIT_MSG=$(git log -1 --pretty=%B)
          echo "Commit message: $COMMIT_MSG"
          
          # Determine bump type based on commit message
          if echo "$COMMIT_MSG" | grep -q "BREAKING CHANGE"; then
            echo "bump_type=major" >> $GITHUB_OUTPUT
            echo "Bump type: major (breaking change detected)"
          elif echo "$COMMIT_MSG" | grep -q "^feat:"; then
            echo "bump_type=minor" >> $GITHUB_OUTPUT
            echo "Bump type: minor (feature detected)"
          elif echo "$COMMIT_MSG" | grep -q "^fix:"; then
            echo "bump_type=patch" >> $GITHUB_OUTPUT
            echo "Bump type: patch (fix detected)"
          else
            echo "bump_type=patch" >> $GITHUB_OUTPUT
            echo "Bump type: patch (default)"
          fi

      - name: Calculate new version
        id: bump_version
        run: |
          CURRENT_VERSION="${{ steps.current_version.outputs.current_version }}"
          BUMP_TYPE="${{ steps.bump_type.outputs.bump_type }}"
          
          # Parse current version
          IFS='.' read -r MAJOR MINOR PATCH <<< "$CURRENT_VERSION"
          
          # Bump version based on type
          case $BUMP_TYPE in
            "major")
              MAJOR=$((MAJOR + 1))
              MINOR=0
              PATCH=0
              ;;
            "minor")
              MINOR=$((MINOR + 1))
              PATCH=0
              ;;
            "patch")
              PATCH=$((PATCH + 1))
              ;;
          esac
          
          NEW_VERSION="$MAJOR.$MINOR.$PATCH"
          echo "newTag=$NEW_VERSION" >> $GITHUB_OUTPUT
          echo "New version: $NEW_VERSION"

      - name: Create and push tag
        if: github.ref == 'refs/heads/master'
        run: |
          NEW_VERSION="${{ steps.bump_version.outputs.newTag }}"
          TAG_NAME="v$NEW_VERSION"
          
          # Check if tag already exists
          if git tag -l "$TAG_NAME" | grep -q "$TAG_NAME"; then
            echo "Tag $TAG_NAME already exists, skipping tag creation"
          else
            # Create tag
            git tag -a "$TAG_NAME" -m "Release $TAG_NAME"
            echo "Created tag: $TAG_NAME"
            
            # Push tag
            git push origin "$TAG_NAME"
            echo "Pushed tag: $TAG_NAME"
          fi

  # ========================= BUILDING PHASE =========================
  
  # Consolidated Building Matrix
  build-all:
    name: Build
    runs-on: ubuntu-latest
    needs: [version-bump]
    if: (github.event_name == 'push') || github.event.inputs.run_build == 'true'
    strategy:
      matrix:
        build-type: [documentation, docker, package]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        if: matrix.build-type != 'docker'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Set up Node.js ${{ env.NODE_VERSION }}
        if: matrix.build-type == 'documentation'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Set up Docker Buildx
        if: matrix.build-type == 'docker'
        uses: docker/setup-buildx-action@v3

      - name: Install Python dependencies
        if: matrix.build-type != 'docker'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/requirements.txt
          if [ "${{ matrix.build-type }}" = "documentation" ]; then
            pip install sphinx sphinx-autodoc-typehints
          fi
          if [ "${{ matrix.build-type }}" = "package" ]; then
            pip install build setuptools wheel
          fi

      - name: Install Mermaid CLI
        if: matrix.build-type == 'documentation'
        run: npm install -g @mermaid-js/mermaid-cli

      - name: Build documentation
        if: matrix.build-type == 'documentation'
        run: |
          # Run the comprehensive documentation automation script
          # This handles: mmd generation, image conversion, API docs, and HTML build
          python docs/auto_generate_docs.py

      - name: Build Docker image
        if: matrix.build-type == 'docker'
        run: |
          VERSION="${{ needs.version-bump.outputs.version }}"
          BUILD_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          
          # Create a temporary requirements file without the local wheel
          cp requirements/requirements.txt /tmp/requirements-docker.txt
          # Remove any local wheel references and add CARLA from PyPI
          sed -i '/\.\/wheels\/carla/d' /tmp/requirements-docker.txt
          echo "carla==0.10.0" >> /tmp/requirements-docker.txt
          
          # Build production image with fixed requirements
          docker build -f deployment/docker/Dockerfile -t ${{ env.DOCKER_IMAGE }}:$VERSION \
            --build-arg VERSION=$VERSION \
            --build-arg DOCKER_IMAGE_TAG=$VERSION \
            --build-arg BUILD_TIME=$BUILD_TIME \
            --build-arg REQUIREMENTS_FILE=/tmp/requirements-docker.txt \
            .
          
          # Tag as latest
          docker tag ${{ env.DOCKER_IMAGE }}:$VERSION ${{ env.DOCKER_IMAGE }}:latest
          
          echo "Docker image built successfully: ${{ env.DOCKER_IMAGE }}:$VERSION"

      - name: Build Python package
        if: matrix.build-type == 'package'
        run: |
          # Update version in __init__.py with bumped version
          NEW_VERSION="${{ needs.version-bump.outputs.version }}"
          if [ -n "$NEW_VERSION" ]; then
            sed -i "s/__version__ = .*/__version__ = \"$NEW_VERSION\"/" carla_simulator/__init__.py
            echo "Updated version to $NEW_VERSION"
          fi
          
          # Build package
          python -m build

      - name: Upload documentation artifacts
        if: matrix.build-type == 'documentation'
        uses: actions/upload-artifact@v4
        with:
          name: html-docs
          path: docs/_build/html/

      - name: Upload documentation source
        if: matrix.build-type == 'documentation'
        uses: actions/upload-artifact@v4
        with:
          name: docs-source
          path: |
            docs/
            mmd/
            .readthedocs.yaml

      - name: Upload Python package
        if: matrix.build-type == 'package'
        uses: actions/upload-artifact@v4
        with:
          name: python-package
          path: dist/

  # ========================= PUBLISH PHASE =========================

  # Publish to PyPI
  publish-to-pypi:
    name: Publish to PyPI
    runs-on: ubuntu-latest
    needs: [validate-and-prepare, version-bump]
    if: (github.event_name == 'push' && github.ref == 'refs/heads/master') || (github.event_name == 'workflow_dispatch' && github.event.inputs.run_pypi_publish == 'true')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-publish-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-publish-

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip
          pip install build setuptools wheel twine

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: python-package
          path: dist/

      - name: Verify PyPI token
        run: |
          echo "Checking PyPI token..."
          if [ -z "${{ secrets.PYPI_TOKEN }}" ]; then
            echo "Error: PYPI_TOKEN is not set"
            exit 1
          fi
          echo "PyPI token is set"

      - name: List files to upload
        run: ls -la dist/

      - name: Check if PyPI package already exists
        id: check_pypi
        run: |
          # Check if the specific version already exists on PyPI
          if python -m twine check dist/* | grep -q "PASSED"; then
            # Try to check if version exists (this is a simple check)
            echo "checking_pypi=true" >> $GITHUB_OUTPUT
            echo "PyPI package version ${{ needs.version-bump.outputs.version }} will be checked during upload"
          else
            echo "checking_pypi=false" >> $GITHUB_OUTPUT
            echo "PyPI package validation failed"
          fi

      - name: Publish to PyPI
        if: steps.check_pypi.outputs.checking_pypi == 'true'
        run: |
          echo "Uploading to PyPI..."
          python -m twine upload --skip-existing --verbose dist/*
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}

  # Publish Docker Images
  publish-docker:
    name: Publish Docker Images
    runs-on: ubuntu-latest
    needs: [build-all, version-bump]
    if: (github.event_name == 'push' && github.ref == 'refs/heads/master') || (github.event_name == 'workflow_dispatch' && github.event.inputs.run_docker_publish == 'true')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Check Docker credentials
        run: |
          if [ -z "${{ secrets.DOCKERHUB_USERNAME }}" ] || [ -z "${{ secrets.DOCKERHUB_TOKEN }}" ]; then
            echo "❌ Docker Hub credentials not configured. Skipping Docker publish."
            echo "Please set DOCKERHUB_USERNAME and DOCKERHUB_TOKEN secrets in repository settings."
            exit 1
          fi

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and push Docker images
        run: |
          VERSION="${{ needs.version-bump.outputs.version }}"
          BUILD_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          
          # Create a temporary requirements file without the local wheel
          cp requirements/requirements.txt /tmp/requirements-docker.txt
          # Remove any local wheel references and add CARLA from PyPI
          sed -i '/\.\/wheels\/carla/d' /tmp/requirements-docker.txt
          echo "carla==0.10.0" >> /tmp/requirements-docker.txt
          
          # Build and push in one step using buildx with caching
          docker buildx build \
            --platform linux/amd64,linux/arm64 \
            --push \
            --cache-from type=gha \
            --cache-to type=gha,mode=max \
            -f deployment/docker/Dockerfile \
            -t ${{ env.DOCKER_IMAGE }}:$VERSION \
            -t ${{ env.DOCKER_IMAGE }}:latest \
            --build-arg VERSION=$VERSION \
            --build-arg DOCKER_IMAGE_TAG=$VERSION \
            --build-arg BUILD_TIME=$BUILD_TIME \
            --build-arg REQUIREMENTS_FILE=/tmp/requirements-docker.txt \
            .
          
          echo "✅ Docker images pushed successfully: ${{ env.DOCKER_IMAGE }}:latest and ${{ env.DOCKER_IMAGE }}:$VERSION"

  # ========================= RELEASE PHASE =========================

  create-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: [build-all]
    if: (github.event_name == 'push' && github.ref == 'refs/heads/master') || (github.event_name == 'workflow_dispatch' && github.event.inputs.run_github_release == 'true')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download documentation artifacts
        uses: actions/download-artifact@v4
        with:
          name: html-docs
          path: docs-html
        continue-on-error: true

      - name: Download Python package artifacts
        uses: actions/download-artifact@v4
        with:
          name: python-package
          path: python-pkg
        continue-on-error: true

      - name: Create Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: v${{ needs.build-all.outputs.version }}
          release_name: Release v${{ needs.build-all.outputs.version }}
          body: |
            ## Release v${{ needs.build-all.outputs.version }}
            
            ### Changes
            - Automated release from master branch
            
            ### Downloads
            - Docker images available on Docker Hub
            - Python package available on PyPI
            
            ### Test Results
            All tests passed successfully before release.
          draft: false
          prerelease: false

      - name: Upload release assets
        run: |
          # Upload Python package if available
          if [ -d "python-pkg" ]; then
            for file in python-pkg/*; do
              if [ -f "$file" ]; then
                echo "Uploading $file to release..."
                gh release upload v${{ needs.build-all.outputs.version }} "$file"
              fi
            done
          else
            echo "⚠️  Python package artifacts not found, skipping upload"
          fi
          
          # Upload documentation if available
          if [ -d "docs-html" ]; then
            echo "Uploading documentation to release..."
            tar -czf docs.tar.gz -C docs-html .
            gh release upload v${{ needs.build-all.outputs.version }} docs.tar.gz
          else
            echo "⚠️  Documentation artifacts not found, skipping upload"
          fi
          
          echo "✅ Release assets uploaded successfully"

  # ========================= CLEANUP PHASE =========================
  
  # Cleanup on failure
  cleanup-on-failure:
    name: Cleanup on Failure
    runs-on: ubuntu-latest
    if: failure() && github.ref == 'refs/heads/master'
    needs: [version-bump]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Delete git tag on failure
        run: |
          NEW_VERSION="${{ needs.version-bump.outputs.version }}"
          TAG_NAME="v$NEW_VERSION"
          
          # Check if tag exists and delete it
          if git tag -l "$TAG_NAME" | grep -q "$TAG_NAME"; then
            echo "Deleting tag $TAG_NAME due to workflow failure"
            git tag -d "$TAG_NAME"
            git push origin ":refs/tags/$TAG_NAME"
            echo "✅ Tag $TAG_NAME deleted successfully"
          else
            echo "Tag $TAG_NAME does not exist, nothing to delete"
          fi

  # ========================= VALIDATION PHASE =========================
  
  # Validate and Prepare for Publishing
  validate-and-prepare:
    name: Validate and Prepare
    runs-on: ubuntu-latest
    needs: [test-all, build-all, version-bump]
    if: (github.event_name == 'push') || github.event.inputs.run_build == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Validate all required jobs passed
        run: |
          echo "🔍 Validating all required jobs..."
          
          # Check test jobs
          if [ "${{ needs.test-all.result }}" != "success" ]; then
            echo "❌ Tests failed"
            exit 1
          fi
          
          # Check build jobs
          if [ "${{ needs.build-all.result }}" != "success" ]; then
            echo "❌ Build failed"
            exit 1
          fi
          
          # Check version bump
          if [ "${{ needs.version-bump.result }}" != "success" ]; then
            echo "❌ Version bump failed"
            exit 1
          fi
          
          echo "✅ All required jobs passed successfully!"
          echo "🚀 Ready for publishing..."

      - name: Final Codecov upload
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Download Python package artifacts
        uses: actions/download-artifact@v4
        with:
          name: python-package
          path: dist/

      - name: List package contents
        run: |
          echo "📦 Package contents:"
          ls -la dist/
          echo "✅ Package downloaded successfully" 