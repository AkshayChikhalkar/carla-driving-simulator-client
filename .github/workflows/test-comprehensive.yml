name: Comprehensive Tests

on:
  # Only trigger on PRs and manual dispatch
  # Production and development builds handle their own testing
  pull_request:
    branches: [ master, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"

jobs:
  # Backend Tests - Carla Simulator
  test-carla-simulator:
    name: Test Carla Simulator
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11]
        test-path: ["carla_simulator/tests"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/requirements.txt
          pip install pytest-cov pytest-html pytest-xdist

      - name: Run Carla Simulator tests
        run: |
          python -m pytest ${{ matrix.test-path }} \
            --cov=carla_simulator \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --html=reports/carla-simulator-test-report.html \
            --self-contained-html \
            -v \
            --tb=short
        env:
          TESTING: "true"
          DATABASE_URL: "sqlite:///:memory:"
          CONFIG_TENANT_ID: "1"

      - name: Upload Carla Simulator test coverage
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: carla-simulator
          name: carla-simulator-coverage
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload Carla Simulator test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: carla-simulator-test-results
          path: |
            reports/carla-simulator-test-report.html
            htmlcov/

  # Backend Tests - Web Backend
  test-web-backend:
    name: Test Web Backend
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11]
        test-path: ["web/backend/tests"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/requirements.txt
          pip install pytest-cov pytest-html pytest-xdist

      - name: Run Web Backend tests
        run: |
          python -m pytest ${{ matrix.test-path }} \
            --cov=web.backend \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --html=reports/web-backend-test-report.html \
            --self-contained-html \
            -v \
            --tb=short
        env:
          TESTING: "true"
          WEB_FILE_LOGS_ENABLED: "false"
          DISABLE_AUTH_FOR_TESTING: "true"
          DATABASE_URL: "sqlite:///:memory:"
          CONFIG_TENANT_ID: "1"

      - name: Upload Web Backend test coverage
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: web-backend
          name: web-backend-coverage
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload Web Backend test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: web-backend-test-results
          path: |
            reports/web-backend-test-report.html
            htmlcov/

  # Frontend Tests
  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: web/frontend/package-lock.json

      - name: Install frontend dependencies
        run: npm ci
        working-directory: web/frontend

      - name: Run frontend tests
        run: npm run test:ci
        working-directory: web/frontend
        env:
          CI: true
          NODE_ENV: test

      - name: Upload frontend test coverage
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          slug: akshaychikhalkar/carla-driving-simulator-client
          flags: frontend
          name: frontend-coverage
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload frontend test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: frontend-test-results
          path: web/frontend/coverage/

  # Integration Tests (if any)
  test-integration:
    name: Test Integration
    runs-on: ubuntu-latest
    needs: [test-carla-simulator, test-web-backend, test-frontend]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/requirements.txt
          pip install pytest-cov pytest-html pytest-xdist

      - name: Run integration tests (if any)
        run: |
          # Check if there are any integration tests
          if [ -d "tests" ] && [ "$(ls -A tests)" ]; then
            python -m pytest tests \
              --cov=. \
              --cov-report=xml \
              --cov-report=html \
              --cov-report=term-missing \
              --html=reports/integration-test-report.html \
              --self-contained-html \
              -v \
              --tb=short
          else
            echo "No integration tests found"
          fi
        env:
          TESTING: "true"
          DATABASE_URL: "sqlite:///:memory:"
          CONFIG_TENANT_ID: "1"

      - name: Upload integration test coverage
        uses: codecov/codecov-action@v5
        if: success()
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: integration
          name: integration-coverage
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            reports/integration-test-report.html
            htmlcov/

  # Test Summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-carla-simulator, test-web-backend, test-frontend, test-integration]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-results

      - name: Generate test summary
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check Carla Simulator tests
          if [ "${{ needs.test-carla-simulator.result }}" == "success" ]; then
            echo "✅ **Carla Simulator Tests**: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Carla Simulator Tests**: FAILED" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check Web Backend tests
          if [ "${{ needs.test-web-backend.result }}" == "success" ]; then
            echo "✅ **Web Backend Tests**: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Web Backend Tests**: FAILED" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check Frontend tests
          if [ "${{ needs.test-frontend.result }}" == "success" ]; then
            echo "✅ **Frontend Tests**: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Frontend Tests**: FAILED" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check Integration tests
          if [ "${{ needs.test-integration.result }}" == "success" ]; then
            echo "✅ **Integration Tests**: PASSED" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.test-integration.result }}" == "skipped" ]; then
            echo "⏭️ **Integration Tests**: SKIPPED (no tests found)" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Integration Tests**: FAILED" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📊 **Coverage Reports**: Available in the artifacts" >> $GITHUB_STEP_SUMMARY
          echo "📋 **Test Reports**: Available in the artifacts" >> $GITHUB_STEP_SUMMARY

      - name: Fail if any tests failed
        if: |
          needs.test-carla-simulator.result != 'success' ||
          needs.test-web-backend.result != 'success' ||
          needs.test-frontend.result != 'success' ||
          (needs.test-integration.result != 'success' && needs.test-integration.result != 'skipped')
        run: |
          echo "❌ Some tests failed. Please check the test results above."
          exit 1
